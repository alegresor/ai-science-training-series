{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOnyVjrbiTAx"
      },
      "source": [
        "# CIFAR-10 dataset classification with CNNs\n",
        "\n",
        "Author: Tanwi Mallick, adapting codes from Bethany Lusch, Prasanna Balprakash, Corey Adams, and Kyle Felker\n",
        "\n",
        "In this notebook, we'll continue the CIFAR-10 problem using the Keras API (as included in the TensorFlow library) and incorporating convolutional layers.\n",
        "\n",
        "First, the needed imports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Rf6sSdEuiTAy"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTSQWikSiTAz"
      },
      "source": [
        "## CIFAR-10 data set\n",
        "\n",
        "Again we'll load the cifar10 data set. CIFAR-10 dataset contains 32x32 color images from 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck. If you haven't downloaded it already, it could take a while."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s39mFyojiTAz"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train = x_train.astype(numpy.float32)\n",
        "x_test  = x_test.astype(numpy.float32)\n",
        "\n",
        "x_train /= 255.\n",
        "x_test  /= 255.\n",
        "\n",
        "y_train = y_train.astype(numpy.int32)\n",
        "y_test  = y_test.astype(numpy.int32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIoSogX8iTA0"
      },
      "source": [
        "This time we won't flatten the images. \n",
        "\n",
        "The training data (`X_train`) is a 3rd-order tensor of size (50000, 32, 32), i.e. it consists of 50000 images of size 32x32 pixels. \n",
        "\n",
        "`y_train` is a 50000-dimensional vector containing the correct classes ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') for each training sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGIYM3lZiTA0"
      },
      "source": [
        "## Convolutional neural network (CNN)\n",
        "\n",
        "CNN is a type of deep learning model for processing data that has a grid pattern, such as images.\n",
        "\n",
        "Let's use a small model that includes convolutional layers\n",
        "\n",
        "- The Conv2D layers operate on 2D matrices so we input the digit images directly to the model.\n",
        "    - The two Conv2D layers belows learn 32 and 64 filters respectively. \n",
        "    - They are learning filters for 3x3 windows.\n",
        "- The MaxPooling2D layer reduces the spatial dimensions, that is, makes the image smaller.\n",
        "    - It downsamples by taking the maximum value in the window \n",
        "    - The pool size of (2, 2) below means the windows are 2x2. \n",
        "    - Helps in extracting important features and reduce computation\n",
        "- The Flatten layer flattens the 2D matrices into vectors, so we can then switch to Dense layers as in the MLP model.\n",
        "\n",
        "See https://keras.io/layers/convolutional/, https://keras.io/layers/pooling/ for more information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9gCk5DNiTA0"
      },
      "source": [
        "![conv layer](images/conv_layer.png)\n",
        "Image credit: [Jason Brownlee](https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nah6hbeiTA0"
      },
      "source": [
        "![conv layer](images/conv.png)\n",
        "Image credit: [Anh H. Reynolds](https://anhreynolds.com/blogs/cnn.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fza-677EiTA1"
      },
      "source": [
        "\n",
        "<img src=\"images/MaxpoolSample2.png\" width=\"600\" hight=\"600\" align=\"left\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "18Qe4RaNiTA1"
      },
      "outputs": [],
      "source": [
        "class CIFAR10Classifier(tf.keras.models.Model):\n",
        "\n",
        "    def __init__(self, activation=tf.nn.tanh):\n",
        "        tf.keras.models.Model.__init__(self)\n",
        "        self.conv_1 = tf.keras.layers.Conv2D(32, [3, 3], activation='relu')\n",
        "        self.pool_1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
        "        self.conv_2 = tf.keras.layers.Conv2D(64, [3, 3], activation='relu')\n",
        "        self.pool_2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
        "        self.conv_3 = tf.keras.layers.Conv2D(64, [3, 3], activation='relu')\n",
        "        self.pool_3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))\n",
        "        self.dense_4 = tf.keras.layers.Dense(64, activation='relu')\n",
        "        self.dense_fin = tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv_1(inputs)\n",
        "        x = self.pool_1(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.pool_2(x)\n",
        "        x = self.conv_3(x)\n",
        "        x = self.pool_3(x)\n",
        "        x = tf.keras.layers.Flatten()(x)\n",
        "        x = self.dense_4(x)\n",
        "        x = self.dense_fin(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgFZ8aCdiTA1"
      },
      "source": [
        "### Simple training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk0QAMGkiTA2"
      },
      "source": [
        "Here is a concise way to train the network, like we did in the previous notebook. We'll see a more verbose approach below that allows more performance tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HHes0oMxiTA2"
      },
      "outputs": [],
      "source": [
        "def train_network_concise(_batch_size, _n_training_epochs, _lr):\n",
        "\n",
        "    cnn_model = CIFAR10Classifier()\n",
        "\n",
        "    cnn_model.compile(\n",
        "        loss = \"sparse_categorical_crossentropy\", \n",
        "        optimizer = \"adam\", \n",
        "        metrics = ['accuracy'])\n",
        "    \n",
        "    history = cnn_model.fit(x_train, y_train, batch_size=_batch_size, epochs=_n_training_epochs)\n",
        "    return history, cnn_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOnsOKG6iTA2",
        "outputId": "e5b8e62a-c22d-4802-ffa5-b32d5266942a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/64\n",
            "49/49 [==============================] - 12s 34ms/step - loss: 2.0218 - accuracy: 0.2563\n",
            "Epoch 2/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 1.6569 - accuracy: 0.3986\n",
            "Epoch 3/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 1.5201 - accuracy: 0.4472\n",
            "Epoch 4/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 1.4446 - accuracy: 0.4737\n",
            "Epoch 5/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 1.3781 - accuracy: 0.5043\n",
            "Epoch 6/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 1.3302 - accuracy: 0.5248\n",
            "Epoch 7/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 1.2903 - accuracy: 0.5406\n",
            "Epoch 8/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 1.2642 - accuracy: 0.5504\n",
            "Epoch 9/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 1.2237 - accuracy: 0.5676\n",
            "Epoch 10/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 1.1774 - accuracy: 0.5871\n",
            "Epoch 11/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 1.1664 - accuracy: 0.5893\n",
            "Epoch 12/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 1.1322 - accuracy: 0.6019\n",
            "Epoch 13/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 1.1078 - accuracy: 0.6133\n",
            "Epoch 14/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 1.1010 - accuracy: 0.6165\n",
            "Epoch 15/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 1.0782 - accuracy: 0.6256\n",
            "Epoch 16/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 1.0484 - accuracy: 0.6364\n",
            "Epoch 17/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 1.0511 - accuracy: 0.6358\n",
            "Epoch 18/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 1.0281 - accuracy: 0.6423\n",
            "Epoch 19/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 1.0039 - accuracy: 0.6529\n",
            "Epoch 20/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.9893 - accuracy: 0.6575\n",
            "Epoch 21/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.9885 - accuracy: 0.6585\n",
            "Epoch 22/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.9709 - accuracy: 0.6639\n",
            "Epoch 23/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.9532 - accuracy: 0.6701\n",
            "Epoch 24/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.9438 - accuracy: 0.6736\n",
            "Epoch 25/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.9383 - accuracy: 0.6767\n",
            "Epoch 26/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.9268 - accuracy: 0.6809\n",
            "Epoch 27/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.9158 - accuracy: 0.6851\n",
            "Epoch 28/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.8949 - accuracy: 0.6925\n",
            "Epoch 29/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.8922 - accuracy: 0.6941\n",
            "Epoch 30/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.8838 - accuracy: 0.6951\n",
            "Epoch 31/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.8728 - accuracy: 0.7010\n",
            "Epoch 32/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.8650 - accuracy: 0.7022\n",
            "Epoch 33/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.8563 - accuracy: 0.7053\n",
            "Epoch 34/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.8579 - accuracy: 0.7066\n",
            "Epoch 35/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.8372 - accuracy: 0.7133\n",
            "Epoch 36/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.8208 - accuracy: 0.7189\n",
            "Epoch 37/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.8183 - accuracy: 0.7190\n",
            "Epoch 38/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.8247 - accuracy: 0.7161\n",
            "Epoch 39/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.8175 - accuracy: 0.7177\n",
            "Epoch 40/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.8046 - accuracy: 0.7257\n",
            "Epoch 41/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.7941 - accuracy: 0.7281\n",
            "Epoch 42/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.7990 - accuracy: 0.7265\n",
            "Epoch 43/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.7895 - accuracy: 0.7292\n",
            "Epoch 44/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.7779 - accuracy: 0.7327\n",
            "Epoch 45/64\n",
            "49/49 [==============================] - 2s 33ms/step - loss: 0.7622 - accuracy: 0.7388\n",
            "Epoch 46/64\n",
            "49/49 [==============================] - 2s 32ms/step - loss: 0.7595 - accuracy: 0.7418\n",
            "Epoch 47/64\n",
            "49/49 [==============================] - 2s 32ms/step - loss: 0.7449 - accuracy: 0.7457\n",
            "Epoch 48/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.7555 - accuracy: 0.7423\n",
            "Epoch 49/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.7470 - accuracy: 0.7448\n",
            "Epoch 50/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.7382 - accuracy: 0.7477\n",
            "Epoch 51/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.7293 - accuracy: 0.7507\n",
            "Epoch 52/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.7182 - accuracy: 0.7560\n",
            "Epoch 53/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.7120 - accuracy: 0.7579\n",
            "Epoch 54/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.7064 - accuracy: 0.7588\n",
            "Epoch 55/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.7106 - accuracy: 0.7562\n",
            "Epoch 56/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.6981 - accuracy: 0.7612\n",
            "Epoch 57/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.6929 - accuracy: 0.7639\n",
            "Epoch 58/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.6931 - accuracy: 0.7633\n",
            "Epoch 59/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.6965 - accuracy: 0.7617\n",
            "Epoch 60/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.6785 - accuracy: 0.7683\n",
            "Epoch 61/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.6768 - accuracy: 0.7700\n",
            "Epoch 62/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.6578 - accuracy: 0.7761\n",
            "Epoch 63/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.6679 - accuracy: 0.7715\n",
            "Epoch 64/64\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.6573 - accuracy: 0.7751\n"
          ]
        }
      ],
      "source": [
        "# This took 55 seconds per epoch on my laptop\n",
        "batch_size = 1024\n",
        "epochs = 64\n",
        "lr = .001\n",
        "history, cnn_model = train_network_concise(batch_size, epochs, lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19foZjNaiTA3"
      },
      "source": [
        "Accuracy for test data.  The model should be better than the non-convolutional model even if you're only patient enough for three epochs. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "Cnow0bgliTA3",
        "outputId": "db410c72-71ab-4fe5-8ca7-da34db46f305"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(history.epoch,history.history['loss'])\n",
        "plt.title('loss')\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(history.epoch,history.history['accuracy'])\n",
        "plt.title('accuracy');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldsJpckOiTA3"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEqZLJa-iTA4"
      },
      "source": [
        "With enough training epochs, the test accuracy should exceed 99%.\n",
        "\n",
        "You can compare your result with the state-of-the art [here](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html). Even more results can be found [here](http://yann.lecun.com/exdb/mnist/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MId072LCiTA4",
        "outputId": "f5ec80f8-2384-4c7a-a4a6-e0c9c793f323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - loss: 0.8646 - accuracy: 0.7052 - 890ms/epoch - 3ms/step\n",
            "accuracy: 70.52%\n",
            "CPU times: user 1.21 s, sys: 172 ms, total: 1.38 s\n",
            "Wall time: 1.15 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "x_test_reshaped = numpy.expand_dims(x_test, -1)\n",
        "scores = cnn_model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"%s: %.2f%%\" % (cnn_model.metrics_names[1], scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBboGII1iTA4"
      },
      "source": [
        "We can also again check the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOU3OLgKiTA4",
        "outputId": "75237e43-b58d-4b3a-bf85-22688fb19e88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix (rows: true classes; columns: predicted classes):\n",
            "\n",
            "[[722  23  53  19  27   2  11  10  86  47]\n",
            " [ 23 779   7  15   6   5   5   8  44 108]\n",
            " [ 64   3 588  69 103  46  67  28  14  18]\n",
            " [ 19  11  80 574  84 111  58  32  11  20]\n",
            " [ 18   5  64  62 704  19  56  59   9   4]\n",
            " [ 19   5  63 212  63 536  25  58   6  13]\n",
            " [  9   3  42  63  41  15 806  13   5   3]\n",
            " [ 15   3  33  61  84  51  10 721   4  18]\n",
            " [ 61  29  16  18  12   6   7   5 808  38]\n",
            " [ 27  58   8  18  13   5   6  20  31 814]]\n",
            "\n",
            "Classification accuracy for each class:\n",
            "\n",
            "0: 0.7220\n",
            "1: 0.7790\n",
            "2: 0.5880\n",
            "3: 0.5740\n",
            "4: 0.7040\n",
            "5: 0.5360\n",
            "6: 0.8060\n",
            "7: 0.7210\n",
            "8: 0.8080\n",
            "9: 0.8140\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print('Confusion matrix (rows: true classes; columns: predicted classes):'); print()\n",
        "predictions = cnn_model.predict(x_test)\n",
        "cm=confusion_matrix(y_test, numpy.argmax(predictions, axis=1), labels=list(range(10)))\n",
        "print(cm); print()\n",
        "\n",
        "print('Classification accuracy for each class:'); print()\n",
        "for i,j in enumerate(cm.diagonal()/cm.sum(axis=1)): print(\"%d: %.4f\" % (i,j))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oN_BAlI_iTA5"
      },
      "source": [
        "### More verbose training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4BkLqeUiTA5"
      },
      "source": [
        "This approach explicitly handles the looping over data. It will be helpful this afternoon for diving in and optimizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hRAHG1A8iTA5"
      },
      "outputs": [],
      "source": [
        "def compute_loss(y_true, y_pred):\n",
        "    # if labels are integers, use sparse categorical crossentropy\n",
        "    # network's final layer is softmax, so from_logtis=False\n",
        "    scce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    # if labels are one-hot encoded, use standard crossentropy\n",
        "\n",
        "    return scce(y_true, y_pred)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EXQr32cviTA5"
      },
      "outputs": [],
      "source": [
        "def forward_pass(model, batch_data, y_true):\n",
        "    y_pred = model(batch_data)\n",
        "    loss = compute_loss(y_true, y_pred)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nldGtSUCiTA5"
      },
      "outputs": [],
      "source": [
        "# Here is a function that will manage the training loop for us:\n",
        "\n",
        "def train_loop(batch_size, n_training_epochs, model, opt):\n",
        "    \n",
        "    @tf.function()\n",
        "    def train_iteration(data, y_true, model, opt):\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = forward_pass(model, data, y_true)\n",
        "\n",
        "        trainable_vars = model.trainable_variables\n",
        "\n",
        "        # Apply the update to the network (one at a time):\n",
        "        grads = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        opt.apply_gradients(zip(grads, trainable_vars))\n",
        "        return loss\n",
        "\n",
        "    for i_epoch in range(n_training_epochs):\n",
        "        print(\"beginning epoch %d\" % i_epoch)\n",
        "        start = time.time()\n",
        "\n",
        "        epoch_steps = int(50000/batch_size)\n",
        "        dataset.shuffle(50000) # Shuffle the whole dataset in memory\n",
        "        batches = dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
        "        \n",
        "        for i_batch, (batch_data, y_true) in enumerate(batches):\n",
        "            batch_data = tf.reshape(batch_data, [-1, 32, 32, 3])\n",
        "            loss = train_iteration(batch_data, y_true, model, opt)\n",
        "            \n",
        "        end = time.time()\n",
        "        print(\"took %1.1f seconds for epoch #%d\" % (end-start, i_epoch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MLRN-OBSiTA6"
      },
      "outputs": [],
      "source": [
        "def train_network(_batch_size, _n_training_epochs, _lr):\n",
        "\n",
        "    mnist_model = CIFAR10Classifier()\n",
        "\n",
        "    opt = tf.keras.optimizers.Adam(_lr)\n",
        "\n",
        "    train_loop(_batch_size, _n_training_epochs, mnist_model, opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJG0jEURiTA6",
        "outputId": "918239d4-f169-4949-efad-1e40aeec4164"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "beginning epoch 0\n",
            "took 2.4 seconds for epoch #0\n",
            "beginning epoch 1\n",
            "took 1.4 seconds for epoch #1\n",
            "beginning epoch 2\n",
            "took 1.4 seconds for epoch #2\n"
          ]
        }
      ],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "dataset.shuffle(50000)\n",
        "\n",
        "batch_size = 512\n",
        "epochs = 3\n",
        "lr = .01\n",
        "train_network(batch_size, epochs, lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEU_-ti5iTA6"
      },
      "source": [
        "# Homework: improve the accuracy of this model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsbsCHKFiTA6"
      },
      "source": [
        "Update this notebook to ensure more accuracy. How high can it be raised? Changes like increasing the number of epochs, altering the learning weight, altering the number of neurons the hidden layer, chnaging the optimizer, etc. could be made directly in the notebook. You can also change the model specification by expanding the network's layer. The current notebook's training accuracy is roughly 58.69%, although it varies randomly.\n",
        "\n",
        "I changed the model earlier in the notebook to achieve over 75% accuracy compared to the around 59% accuracy achieved earlier. I imagine if I let it run for more than 64 epochs I could continue improving the accuracy up to 99%!"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4ZBdhm2Uqwa-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}